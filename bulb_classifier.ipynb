{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.utils as utils\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n8 Class classification problem \\n\\nInitially work on trying to classifiy based on google search scraped pictures of these lightbulbs.\\nThe problem with this is that they nearly always have a white backgroud and are not realistic of a phone camera version\\nof a picture of the light bulb\\n'current search: B15 light bulbs'\\n\\nClasses\\nE27 light bulbs\\nE14 light bulbs\\nB22 light bulbs\\nB15 light bulbs\\nGU10 light bulbs\\nG4\\nG9\\nMR16\\n\\n\\nNeed to also buy some examples of the light bulbs as a way of building up my own dataset that might be more realistic.\\n\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "8 Class classification problem \n",
    "\n",
    "Initially work on trying to classifiy based on google search scraped pictures of these lightbulbs.\n",
    "The problem with this is that they nearly always have a white backgroud and are not realistic of a phone camera version\n",
    "of a picture of the light bulb\n",
    "'current search: B15 light bulbs'\n",
    "\n",
    "Classes\n",
    "E27 light bulbs\n",
    "E14 light bulbs\n",
    "B22 light bulbs\n",
    "B15 light bulbs\n",
    "GU10 light bulbs\n",
    "G4\n",
    "G9\n",
    "MR16\n",
    "\n",
    "\n",
    "Need to also buy some examples of the light bulbs as a way of building up my own dataset that might be more realistic.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to rename all the file names to avoid really long file names and make it easier to know which bulb it is. \n",
    "\n",
    "def file_rename():\n",
    "    # Function to rename multiple files \n",
    "    for bulb_type in ['B15','B22','E14', 'E27', 'G4', 'G9','GU10', 'MR16']:\n",
    "\n",
    "        location = r\"C:\\Users\\awalker8\\Documents\\COVID_Furlow\\bulb_class\\bulb_data\"\n",
    "        location = location + '\\\\' + bulb_type + '\\\\'\n",
    "        print(location)\n",
    "        for count, filename in enumerate(os.listdir(location)): \n",
    "            dst = bulb_type + str(count) + \".jpg\"\n",
    "            src = location + filename \n",
    "            dst = location + dst \n",
    "            # rename() function will \n",
    "            # rename all the files \n",
    "            os.rename(src, dst) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pytorch dataset, and then dataloader to allow for mini-batch processing. \n",
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomSizedCrop(128),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "light_bulbs = datasets.ImageFolder(root=r'C:\\Users\\awalker8\\Documents\\COVID_Furlow\\bulb_class\\bulb_data',\n",
    "                                           transform=data_transform)\n",
    "    \n",
    "\n",
    "# If i use more than 0 num_workers get an issue with file truncation??\n",
    "dataloader = torch.utils.data.DataLoader(light_bulbs,\n",
    "                                             batch_size=64, shuffle=True,\n",
    "                                             num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 4489\n",
       "    Root location: C:\\Users\\awalker8\\Documents\\COVID_Furlow\\bulb_class\\bulb_data\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomSizedCrop(size=(128, 128), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, dev_ds, test_ds = torch.utils.data.random_split(dataloader.dataset, (3500,500,489))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in dataloader:\n",
    "#     print(x.shape)\n",
    "#     x.shape[0]\n",
    "#     out = np.reshape(x.numpy()[0,:,:,:],newshape =[x.shape[0],x.shape[2],x.shape[3],x.shape[1]])\n",
    "#     print(out.shape)\n",
    "#     print(out[0,:,:,:].shape)\n",
    "#     plt.imshow(out[0,:,:,:])\n",
    "#     plt.show()\n",
    "    \n",
    "#     #plt.imshow(np.reshape(x.numpy()[0,:,:,:],newshape =[1,64,64,3]))\n",
    "#     #plt.show()\n",
    "#     print(y) # image label\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the weights_init function that takes as input a neural network m and that will initialize all its weights.\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier\n",
    "\n",
    "class bulb_model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(bulb_model, self).__init__()\n",
    "    \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            # add a max pooling layer\n",
    "            nn.MaxPool2d(kernel_size =3 , stride=1, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace = True), \n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias = False), \n",
    "            nn.MaxPool2d(kernel_size =2 , stride=1, padding=0),\n",
    "            nn.BatchNorm2d(256), \n",
    "            nn.LeakyReLU(0.2, inplace = True), \n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(512), \n",
    "            nn.LeakyReLU(0.2, inplace = True), \n",
    "            nn.Conv2d(512, 10, 4, 1, 0, bias = False), \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 512),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bulb_model(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (10): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (13): Conv2d(512, 10, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (14): Flatten()\n",
       "    (15): Linear(in_features=160, out_features=512, bias=True)\n",
       "    (16): Dropout(p=0.2, inplace=False)\n",
       "    (17): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (18): Dropout(p=0.2, inplace=False)\n",
       "    (19): Linear(in_features=128, out_features=10, bias=True)\n",
       "    (20): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_1 = bulb_model()\n",
    "classifier_1.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an optimiser for the classifier\n",
    "optimiser_bulb = optim.Adam(classifier_1.parameters(), lr=0.002, betas = (0.9,0.999))\n",
    "# Create a criterion. Lets use cross entropy loss. \n",
    "criterion = nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1):\n",
    "\n",
    "#     for data, labels in dataloader:\n",
    "#         i = 1\n",
    "#         # push the image through the network\n",
    "#         prediction = classifier_1(data)\n",
    "#         print(prediction)\n",
    "#         print(prediction.shape)\n",
    "#         print(labels)\n",
    "#         if i == 1:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2.2489, 2.2489, 2.2489,  ..., 1.2557, 1.2385, 1.2043],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 1.4612, 1.3927, 1.3242],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 1.3413, 1.2728, 1.2043],\n",
      "          ...,\n",
      "          [2.2318, 2.2318, 2.2318,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2318, 2.2318, 2.2318,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 1.5707, 1.5532, 1.5182],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 1.7808, 1.7108, 1.6408],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 1.6583, 1.5882, 1.5182],\n",
      "          ...,\n",
      "          [2.4111, 2.4111, 2.4111,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4111, 2.4111, 2.4111,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 1.9080, 1.8905, 1.8557],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.1171, 2.0474, 1.9777],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 1.9951, 1.9254, 1.8557],\n",
      "          ...,\n",
      "          [2.6226, 2.6226, 2.6226,  ..., 2.6051, 2.6051, 2.6051],\n",
      "          [2.6226, 2.6226, 2.6226,  ..., 2.6051, 2.6051, 2.6051],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6051, 2.6051, 2.6051]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[1.7523, 1.7694, 1.7865,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [1.7523, 1.7694, 1.7865,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [1.7694, 1.7694, 1.7865,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.8961, 0.6734, 0.3823,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [1.2728, 0.8789, 0.3138,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [1.6495, 1.0502, 0.2111,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[1.9384, 1.9559, 1.9734,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [1.9384, 1.9559, 1.9734,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [1.9559, 1.9559, 1.9734,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0630, 0.8354, 0.5378,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [1.4482, 1.0455, 0.4678,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [1.8333, 1.2206, 0.3627,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.1868, 2.2043, 2.2217,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.1868, 2.2043, 2.2217,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.2043, 2.2043, 2.2217,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [1.3502, 1.1237, 0.8448,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [1.7337, 1.3328, 0.7925,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.1171, 1.5245, 0.6879,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2.2318, 2.2147, 2.2147,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1462, 2.1462, 2.1975,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.0605, 2.0777, 2.1633,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [1.4098, 1.1358, 0.5022,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [1.5982, 0.8447, 0.2111,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [1.7694, 0.6392, 0.0056,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4111, 2.3936, 2.3936,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3235, 2.3235, 2.3761,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.2360, 2.2535, 2.3410,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.6232, 1.3431, 0.6954,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [1.8158, 1.0455, 0.3978,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [1.9909, 0.8354, 0.1877,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6226, 2.6051, 2.6051,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5354, 2.5354, 2.5877,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.4483, 2.4657, 2.5529,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [1.9254, 1.6465, 1.0017,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.1171, 1.3502, 0.7054,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.2914, 1.1411, 0.4962,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2318, 1.9920, 1.2214,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2318, 1.9749, 1.2214,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.9578, 1.2043,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.5364, 0.2796, 0.5193,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [1.5297, 1.7009, 1.8208,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.0777, 1.9920, 1.6667,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.3761, 2.1310, 1.3256,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 2.1134, 1.3256,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3585, 2.0959, 1.3081,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [0.6779, 0.4153, 0.6604,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [1.6933, 1.8683, 1.9909,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.2535, 2.1660, 1.8333,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.4134, 1.6640,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.4134, 1.6640,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.3960, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8971, 0.6356, 0.8797,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [1.9080, 2.0823, 2.2043,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.4657, 2.3786, 2.0474,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.1975, 2.1804, 2.2318],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.1975, 2.1804, 2.2318],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.1975, 2.1804, 2.2318],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6051, 2.6051, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]]])\n",
      "tensor([6, 1, 2, 0, 3, 3, 6, 7, 4, 5, 5, 2, 0, 4, 0, 7, 7, 7, 2, 0, 2, 5, 0, 0,\n",
      "        3, 5, 4, 6, 4, 0, 0, 4, 2, 7, 3, 2, 1, 0, 2, 4, 4, 5, 1, 4, 3, 1, 1, 3,\n",
      "        3, 2, 2, 1, 0, 7, 7, 3, 0, 4, 4, 2, 2, 4, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    i = 1\n",
    "    for data, labels in dataloader:\n",
    "        print(data)\n",
    "        print(labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 64 3 4 4, but got 3-dimensional input of size [3, 128, 128] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c615742f16e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# push the image through the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-dd768ddfc77f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 64 3 4 4, but got 3-dimensional input of size [3, 128, 128] instead"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    i = 1\n",
    "    for data, labels in train_ds:\n",
    "     \n",
    "        # push the image through the network\n",
    "        prediction = classifier_1(data)\n",
    "        \n",
    "        error = criterion(prediction, labels)\n",
    "        print('[%d/%d][%d/%d] Loss: %.4f' % (epoch, 25, i, len(train_ds),error))\n",
    "  \n",
    "        # zero grad\n",
    "        classifier_1.zero_grad()\n",
    "        error.backward()\n",
    "        optimiser_bulb.step()\n",
    "        \n",
    "        #if i == 10:\n",
    "        #   break\n",
    "            \n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Would be good to be able to show images from the loader whenever we fancy. Why can't i get this to work :()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to show a batch\n",
    "def show_bulb_batch(sample_batched):\n",
    "    \n",
    "    \"\"\"Show image for a batch of samples.\"\"\"\n",
    "    images_batch = sample_batched[0][1]\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    grid_border_size = 2\n",
    "\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "    plt.title('Batch from dataloader')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i_batch, sample_batched in enumerate(dataloader):\n",
    "#     print(i_batch)\n",
    "#     print(sample_batched[0][1].shape)\n",
    "#     #ToPILImage(sample_batched[0][1])\n",
    "#     #to_img(sample_batched[0][1])\n",
    "    \n",
    "#     if i_batch ==3:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched[0].size())\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 1:\n",
    "        plt.figure()\n",
    "        show_bulb_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
